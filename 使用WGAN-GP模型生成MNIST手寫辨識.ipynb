{"cells":[{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import cv2"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["class Generator(tf.keras.Model):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.fc = tf.keras.Sequential([\n","            tf.keras.layers.Dense(128, activation='relu'),\n","            tf.keras.layers.Dense(512, activation='relu'),\n","            tf.keras.layers.Dense(28*28, activation='sigmoid'),\n","        ])\n","\n","    def call(self, inputs):\n","        return self.fc(inputs)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["class Discriminator(tf.keras.Model):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.fc = tf.keras.Sequential([\n","            tf.keras.layers.Dense(512, activation='relu'),\n","            tf.keras.layers.Dense(128, activation='relu'),\n","            tf.keras.layers.Dense(1, activation='linear'),\n","        ])\n","\n","    def call(self, inputs):\n","        return self.fc(inputs)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["class WGAN_GP():\n","    def __init__(self):\n","        self.noise_size = 16\n","        self.generator = Generator()\n","        self.discriminator = Discriminator()\n","        self.generator.build(input_shape=(None, self.noise_size))\n","        self.discriminator.build(input_shape=(None, 28*28))\n","        self.g_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","        self.d_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n","\n","    def train(self, dataset, batch_size=1024, epochs=500):\n","        for e in range(epochs):\n","            generator_loss = list()\n","            discriminator_loss = list()\n","            for i in range(int(len(dataset) / batch_size)):\n","                real_image = dataset[i * batch_size: (i+1)*batch_size]\n","                normal_z = np.random.normal(size=(batch_size, self.noise_size))\n","                with tf.GradientTape() as tape:\n","                    d_loss = self.d_loss(self.generator, self.discriminator, normal_z, real_image)\n","                grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n","                self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_variables))\n","                with tf.GradientTape() as tape:\n","                    g_loss = self.g_loss(self.generator, self.discriminator, normal_z)\n","                grads = tape.gradient(g_loss, self.generator.trainable_variables)\n","                self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_variables))\n","                generator_loss.append(g_loss)\n","                discriminator_loss.append(d_loss)\n","            g_l = np.mean(generator_loss)\n","            d_l = np.mean(discriminator_loss)\n","            print(\"epoch: {}/{}, generator loss: {}, discriminator loss: {}\".format(e+1, epochs, g_l, d_l))\n","            if (e+1) % 10 == 0:\n","                self.save_image(\"./WGAN-GP/image_epochs_{}.png\".format(e+1))\n","    \n","    def save_image(self, path):\n","        normal_z = np.random.normal(size=(1, self.noise_size))\n","        image = self.generator.predict(normal_z)\n","        image = np.reshape(image, newshape=(28, 28)) * 255.0\n","        cv2.imwrite(path, image)\n","\n","    @staticmethod\n","    def gradient_penalty(discriminator, real_image, fake_image):\n","        assert real_image.shape[0] == fake_image.shape[0]\n","        batch_size = real_image.shape[0]\n","        eps = tf.random.uniform([batch_size, 1])\n","        inter = eps * real_image + (1. - eps) * fake_image\n","        with tf.GradientTape() as tape:\n","            tape.watch([inter])\n","            d_inter_logits = discriminator(inter)\n","        grads = tape.gradient(d_inter_logits, inter)\n","        grads = tf.reshape(grads, [grads.shape[0], -1])\n","        gp = tf.norm(grads, axis=1)\n","        gp = tf.reduce_mean((gp - 1.) ** 2)\n","        return gp\n","    \n","    @staticmethod\n","    def g_loss(generator, discriminator, noise_z):\n","        fake_image = generator(noise_z)\n","        d_fake_logits = discriminator(fake_image)\n","        loss = - tf.reduce_mean(d_fake_logits)\n","        return loss\n","\n","    @staticmethod\n","    def d_loss(generator, discriminator, noise_z, real_image):\n","        fake_image = generator(noise_z)\n","        d_fake_logits = discriminator(fake_image)\n","        d_real_logits = discriminator(real_image)\n","        gp = WGAN_GP.gradient_penalty(discriminator, real_image, fake_image)\n","        loss = tf.reduce_mean(d_fake_logits) - tf.reduce_mean(d_real_logits) + 10. * gp\n","        return loss, gp\n","    "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["epoch: 1/500, generator loss: 4.7165374755859375, discriminator loss: -2.106144666671753\n","epoch: 2/500, generator loss: 0.4603469967842102, discriminator loss: -1.6288366317749023\n","epoch: 3/500, generator loss: 0.1497013121843338, discriminator loss: -1.8890736103057861\n","epoch: 4/500, generator loss: 0.2547372579574585, discriminator loss: -1.6553547382354736\n","epoch: 5/500, generator loss: 0.2565060555934906, discriminator loss: -1.6102776527404785\n","epoch: 6/500, generator loss: 0.11520905047655106, discriminator loss: -1.421623945236206\n","epoch: 7/500, generator loss: 0.32349395751953125, discriminator loss: -1.3993253707885742\n","epoch: 8/500, generator loss: 0.2909322679042816, discriminator loss: -1.3377583026885986\n","epoch: 9/500, generator loss: 0.06489350646734238, discriminator loss: -1.2587331533432007\n","epoch: 10/500, generator loss: 0.40025752782821655, discriminator loss: -1.1577603816986084\n","1/1 [==============================] - 0s 32ms/step\n","epoch: 11/500, generator loss: 0.22770828008651733, discriminator loss: -1.1084825992584229\n","epoch: 12/500, generator loss: 0.01814775913953781, discriminator loss: -1.062453269958496\n","epoch: 13/500, generator loss: 0.26633575558662415, discriminator loss: -1.024893045425415\n","epoch: 14/500, generator loss: 0.33514490723609924, discriminator loss: -0.9499102830886841\n","epoch: 15/500, generator loss: 0.33434271812438965, discriminator loss: -0.8448182344436646\n","epoch: 16/500, generator loss: 0.3607743978500366, discriminator loss: -0.8859658241271973\n","epoch: 17/500, generator loss: 0.31500306725502014, discriminator loss: -0.8766992092132568\n","epoch: 18/500, generator loss: 0.5051645636558533, discriminator loss: -0.9167977571487427\n","epoch: 19/500, generator loss: 0.5884595513343811, discriminator loss: -0.8375289440155029\n","epoch: 20/500, generator loss: 0.3415187895298004, discriminator loss: -0.848416268825531\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 21/500, generator loss: 0.214610293507576, discriminator loss: -0.7960428595542908\n","epoch: 22/500, generator loss: 0.4950001537799835, discriminator loss: -0.8183504939079285\n","epoch: 23/500, generator loss: 0.45557716488838196, discriminator loss: -0.741174042224884\n","epoch: 24/500, generator loss: 0.39588725566864014, discriminator loss: -0.748190701007843\n","epoch: 25/500, generator loss: 0.28704148530960083, discriminator loss: -0.6681686639785767\n","epoch: 26/500, generator loss: 0.397684782743454, discriminator loss: -0.6814899444580078\n","epoch: 27/500, generator loss: 0.43315303325653076, discriminator loss: -0.6541473865509033\n","epoch: 28/500, generator loss: 0.588995099067688, discriminator loss: -0.704135537147522\n","epoch: 29/500, generator loss: 0.6649374961853027, discriminator loss: -0.656137228012085\n","epoch: 30/500, generator loss: 0.2184637486934662, discriminator loss: -0.7041971683502197\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 31/500, generator loss: 0.29366496205329895, discriminator loss: -0.6388970613479614\n","epoch: 32/500, generator loss: 0.4237765967845917, discriminator loss: -0.668118953704834\n","epoch: 33/500, generator loss: 0.27097946405410767, discriminator loss: -0.6433207392692566\n","epoch: 34/500, generator loss: 0.19441258907318115, discriminator loss: -0.623969554901123\n","epoch: 35/500, generator loss: 0.8138083815574646, discriminator loss: -0.6307724714279175\n","epoch: 36/500, generator loss: 0.5796718001365662, discriminator loss: -0.6676744818687439\n","epoch: 37/500, generator loss: 0.4575188457965851, discriminator loss: -0.6297703981399536\n","epoch: 38/500, generator loss: 0.33496567606925964, discriminator loss: -0.6492956280708313\n","epoch: 39/500, generator loss: -0.009109034202992916, discriminator loss: -0.5932910442352295\n","epoch: 40/500, generator loss: 0.2653646767139435, discriminator loss: -0.5995888113975525\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 41/500, generator loss: 0.15575602650642395, discriminator loss: -0.5861935615539551\n","epoch: 42/500, generator loss: 0.22906580567359924, discriminator loss: -0.5673280954360962\n","epoch: 43/500, generator loss: -0.05568322539329529, discriminator loss: -0.5079384446144104\n","epoch: 44/500, generator loss: 0.4641243815422058, discriminator loss: -0.5704674124717712\n","epoch: 45/500, generator loss: 0.5305266976356506, discriminator loss: -0.549914538860321\n","epoch: 46/500, generator loss: 0.10149750113487244, discriminator loss: -0.530707061290741\n","epoch: 47/500, generator loss: 0.430370569229126, discriminator loss: -0.5299606919288635\n","epoch: 48/500, generator loss: 0.19060061872005463, discriminator loss: -0.5093165040016174\n","epoch: 49/500, generator loss: 0.6271154880523682, discriminator loss: -0.5314124226570129\n","epoch: 50/500, generator loss: 0.2840610444545746, discriminator loss: -0.5026523470878601\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 51/500, generator loss: 0.3218857944011688, discriminator loss: -0.49467524886131287\n","epoch: 52/500, generator loss: 0.2711942493915558, discriminator loss: -0.4877365827560425\n","epoch: 53/500, generator loss: 0.9016777276992798, discriminator loss: -0.5145894885063171\n","epoch: 54/500, generator loss: 0.5206698179244995, discriminator loss: -0.479391485452652\n","epoch: 55/500, generator loss: -0.18743440508842468, discriminator loss: -0.4846498966217041\n","epoch: 56/500, generator loss: 0.6295236349105835, discriminator loss: -0.45739370584487915\n","epoch: 57/500, generator loss: 0.8409435153007507, discriminator loss: -0.4273548126220703\n","epoch: 58/500, generator loss: 0.1765354424715042, discriminator loss: -0.4170214533805847\n","epoch: 59/500, generator loss: 0.42954176664352417, discriminator loss: -0.438399076461792\n","epoch: 60/500, generator loss: 0.13576097786426544, discriminator loss: -0.44869840145111084\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 61/500, generator loss: 0.6014571189880371, discriminator loss: -0.46192482113838196\n","epoch: 62/500, generator loss: 0.12931805849075317, discriminator loss: -0.44122856855392456\n","epoch: 63/500, generator loss: 0.42723348736763, discriminator loss: -0.4113590121269226\n","epoch: 64/500, generator loss: 0.3818415701389313, discriminator loss: -0.4351039528846741\n","epoch: 65/500, generator loss: 0.6037725210189819, discriminator loss: -0.4609810709953308\n","epoch: 66/500, generator loss: 0.3710407614707947, discriminator loss: -0.43995511531829834\n","epoch: 67/500, generator loss: 0.4266512989997864, discriminator loss: -0.4471036195755005\n","epoch: 68/500, generator loss: 0.29687872529029846, discriminator loss: -0.43457815051078796\n","epoch: 69/500, generator loss: 0.21016015112400055, discriminator loss: -0.434470534324646\n","epoch: 70/500, generator loss: 0.6566088199615479, discriminator loss: -0.3968733549118042\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 71/500, generator loss: 0.007545799948275089, discriminator loss: -0.437499463558197\n","epoch: 72/500, generator loss: 0.10228754580020905, discriminator loss: -0.4288966655731201\n","epoch: 73/500, generator loss: 0.38817062973976135, discriminator loss: -0.42034220695495605\n","epoch: 74/500, generator loss: 0.39844849705696106, discriminator loss: -0.407203733921051\n","epoch: 75/500, generator loss: 0.47576695680618286, discriminator loss: -0.3886948823928833\n","epoch: 76/500, generator loss: 0.575200617313385, discriminator loss: -0.4256214499473572\n","epoch: 77/500, generator loss: 0.35721442103385925, discriminator loss: -0.4087032079696655\n","epoch: 78/500, generator loss: 0.23784805834293365, discriminator loss: -0.4220234751701355\n","epoch: 79/500, generator loss: 0.7269781827926636, discriminator loss: -0.397148460149765\n","epoch: 80/500, generator loss: 0.2773752212524414, discriminator loss: -0.40400978922843933\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 81/500, generator loss: 0.2998254597187042, discriminator loss: -0.3897761404514313\n","epoch: 82/500, generator loss: 0.3426969647407532, discriminator loss: -0.4015553593635559\n","epoch: 83/500, generator loss: 0.33249709010124207, discriminator loss: -0.3968299627304077\n","epoch: 84/500, generator loss: 0.4941546618938446, discriminator loss: -0.3684195280075073\n","epoch: 85/500, generator loss: 0.12992805242538452, discriminator loss: -0.4056239426136017\n","epoch: 86/500, generator loss: 0.6504216194152832, discriminator loss: -0.39118704199790955\n","epoch: 87/500, generator loss: 0.40073907375335693, discriminator loss: -0.39126622676849365\n","epoch: 88/500, generator loss: 0.15613725781440735, discriminator loss: -0.39472025632858276\n","epoch: 89/500, generator loss: -0.25668761134147644, discriminator loss: -0.39717763662338257\n","epoch: 90/500, generator loss: 0.17403258383274078, discriminator loss: -0.40718623995780945\n","1/1 [==============================] - 0s 11ms/step\n","epoch: 91/500, generator loss: 0.48356446623802185, discriminator loss: -0.4043004810810089\n","epoch: 92/500, generator loss: 0.24968332052230835, discriminator loss: -0.36916762590408325\n","epoch: 93/500, generator loss: 0.376600980758667, discriminator loss: -0.37899690866470337\n","epoch: 94/500, generator loss: -0.2896135449409485, discriminator loss: -0.34835827350616455\n","epoch: 95/500, generator loss: 0.3594167232513428, discriminator loss: -0.37591904401779175\n","epoch: 96/500, generator loss: 0.13772474229335785, discriminator loss: -0.36400070786476135\n","epoch: 97/500, generator loss: 0.10767455399036407, discriminator loss: -0.38764578104019165\n","epoch: 98/500, generator loss: 0.1648777276277542, discriminator loss: -0.3846123218536377\n","epoch: 99/500, generator loss: 0.18969185650348663, discriminator loss: -0.367456316947937\n","epoch: 100/500, generator loss: 0.09631679952144623, discriminator loss: -0.39561712741851807\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 101/500, generator loss: -0.06846027821302414, discriminator loss: -0.36740583181381226\n","epoch: 102/500, generator loss: -0.2113184779882431, discriminator loss: -0.3888530433177948\n","epoch: 103/500, generator loss: -0.0708971694111824, discriminator loss: -0.38679033517837524\n","epoch: 104/500, generator loss: -0.01086623128503561, discriminator loss: -0.36888864636421204\n","epoch: 105/500, generator loss: 0.07382335513830185, discriminator loss: -0.37328657507896423\n","epoch: 106/500, generator loss: -0.37631547451019287, discriminator loss: -0.3726098835468292\n","epoch: 107/500, generator loss: -0.46431997418403625, discriminator loss: -0.35543495416641235\n","epoch: 108/500, generator loss: -0.22053547203540802, discriminator loss: -0.37094563245773315\n","epoch: 109/500, generator loss: -0.10420717298984528, discriminator loss: -0.3718774616718292\n","epoch: 110/500, generator loss: -0.05604368820786476, discriminator loss: -0.3725491762161255\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 111/500, generator loss: 0.14444002509117126, discriminator loss: -0.36905375123023987\n","epoch: 112/500, generator loss: -0.039264973253011703, discriminator loss: -0.348523885011673\n","epoch: 113/500, generator loss: -0.41645318269729614, discriminator loss: -0.3731139600276947\n","epoch: 114/500, generator loss: -0.3349934220314026, discriminator loss: -0.3656691610813141\n","epoch: 115/500, generator loss: 0.01419105939567089, discriminator loss: -0.3574892580509186\n","epoch: 116/500, generator loss: -0.4824262857437134, discriminator loss: -0.35022032260894775\n","epoch: 117/500, generator loss: -0.3818504512310028, discriminator loss: -0.3596261441707611\n","epoch: 118/500, generator loss: -0.5770429968833923, discriminator loss: -0.37640658020973206\n","epoch: 119/500, generator loss: -0.6416770219802856, discriminator loss: -0.38576024770736694\n","epoch: 120/500, generator loss: -0.09512702375650406, discriminator loss: -0.3724626302719116\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 121/500, generator loss: -0.8162322640419006, discriminator loss: -0.3686511516571045\n","epoch: 122/500, generator loss: -0.3868072032928467, discriminator loss: -0.35583120584487915\n","epoch: 123/500, generator loss: -0.06032908335328102, discriminator loss: -0.33042094111442566\n","epoch: 124/500, generator loss: -0.5891067385673523, discriminator loss: -0.3612046539783478\n","epoch: 125/500, generator loss: 0.002457742113620043, discriminator loss: -0.3350464403629303\n","epoch: 126/500, generator loss: -0.874811589717865, discriminator loss: -0.3686456084251404\n","epoch: 127/500, generator loss: -0.5154446959495544, discriminator loss: -0.37473264336586\n","epoch: 128/500, generator loss: -0.2873569428920746, discriminator loss: -0.37382546067237854\n","epoch: 129/500, generator loss: -0.4533731937408447, discriminator loss: -0.3778650462627411\n","epoch: 130/500, generator loss: -0.6430543661117554, discriminator loss: -0.363107293844223\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 131/500, generator loss: -0.7208953499794006, discriminator loss: -0.3771589398384094\n","epoch: 132/500, generator loss: -0.7551416158676147, discriminator loss: -0.3735872507095337\n","epoch: 133/500, generator loss: -0.36813217401504517, discriminator loss: -0.38148951530456543\n","epoch: 134/500, generator loss: -0.7577304244041443, discriminator loss: -0.3648519217967987\n","epoch: 135/500, generator loss: -0.39490607380867004, discriminator loss: -0.35680291056632996\n","epoch: 136/500, generator loss: -0.6207941770553589, discriminator loss: -0.3666344881057739\n","epoch: 137/500, generator loss: -0.47986525297164917, discriminator loss: -0.3471871316432953\n","epoch: 138/500, generator loss: -0.5883063077926636, discriminator loss: -0.3677382171154022\n","epoch: 139/500, generator loss: -0.5572879314422607, discriminator loss: -0.34898990392684937\n","epoch: 140/500, generator loss: -0.315231055021286, discriminator loss: -0.3529545068740845\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 141/500, generator loss: -0.9598899483680725, discriminator loss: -0.3554815649986267\n","epoch: 142/500, generator loss: -0.4188569188117981, discriminator loss: -0.34746116399765015\n","epoch: 143/500, generator loss: -0.736016035079956, discriminator loss: -0.3636939525604248\n","epoch: 144/500, generator loss: -0.24372373521327972, discriminator loss: -0.34771478176116943\n","epoch: 145/500, generator loss: -0.6480467319488525, discriminator loss: -0.3622472286224365\n","epoch: 146/500, generator loss: -0.35135963559150696, discriminator loss: -0.34398069977760315\n","epoch: 147/500, generator loss: -0.27817320823669434, discriminator loss: -0.3415110111236572\n","epoch: 148/500, generator loss: -0.6843481659889221, discriminator loss: -0.33268749713897705\n","epoch: 149/500, generator loss: -0.6800585389137268, discriminator loss: -0.34959086775779724\n","epoch: 150/500, generator loss: -0.5030872821807861, discriminator loss: -0.330041766166687\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 151/500, generator loss: -0.6883994936943054, discriminator loss: -0.35401609539985657\n","epoch: 152/500, generator loss: -0.31784766912460327, discriminator loss: -0.33443334698677063\n","epoch: 153/500, generator loss: -0.8448657393455505, discriminator loss: -0.3246530294418335\n","epoch: 154/500, generator loss: -0.2583697438240051, discriminator loss: -0.3240753710269928\n","epoch: 155/500, generator loss: 0.17332080006599426, discriminator loss: -0.32550761103630066\n","epoch: 156/500, generator loss: -0.32736021280288696, discriminator loss: -0.3166922330856323\n","epoch: 157/500, generator loss: -0.4502178132534027, discriminator loss: -0.33413228392601013\n","epoch: 158/500, generator loss: -0.3730022609233856, discriminator loss: -0.33598676323890686\n","epoch: 159/500, generator loss: -0.4943891763687134, discriminator loss: -0.3198109567165375\n","epoch: 160/500, generator loss: -0.5389338731765747, discriminator loss: -0.33001649379730225\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 161/500, generator loss: 0.11793894320726395, discriminator loss: -0.3171517848968506\n","epoch: 162/500, generator loss: -0.3244034945964813, discriminator loss: -0.34127873182296753\n","epoch: 163/500, generator loss: -0.4330880343914032, discriminator loss: -0.34558433294296265\n","epoch: 164/500, generator loss: -0.3200419545173645, discriminator loss: -0.3113854229450226\n","epoch: 165/500, generator loss: -0.000863083463627845, discriminator loss: -0.3348560035228729\n","epoch: 166/500, generator loss: -0.5972529649734497, discriminator loss: -0.3338230848312378\n","epoch: 167/500, generator loss: -0.36051058769226074, discriminator loss: -0.3304454982280731\n","epoch: 168/500, generator loss: -0.38982489705085754, discriminator loss: -0.3334452211856842\n","epoch: 169/500, generator loss: -0.4145486056804657, discriminator loss: -0.3195844292640686\n","epoch: 170/500, generator loss: -0.5561324954032898, discriminator loss: -0.3349922299385071\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 171/500, generator loss: -0.2838039994239807, discriminator loss: -0.3414153456687927\n","epoch: 172/500, generator loss: -0.7067505121231079, discriminator loss: -0.33129027485847473\n","epoch: 173/500, generator loss: -0.2952439486980438, discriminator loss: -0.31240177154541016\n","epoch: 174/500, generator loss: -0.5674245357513428, discriminator loss: -0.3170579671859741\n","epoch: 175/500, generator loss: -0.7015448212623596, discriminator loss: -0.3140484392642975\n","epoch: 176/500, generator loss: -0.34478867053985596, discriminator loss: -0.3232881426811218\n","epoch: 177/500, generator loss: 0.2504056394100189, discriminator loss: -0.32530826330184937\n","epoch: 178/500, generator loss: -0.5725305080413818, discriminator loss: -0.33062291145324707\n","epoch: 179/500, generator loss: -0.4413294494152069, discriminator loss: -0.32299330830574036\n","epoch: 180/500, generator loss: 0.04764687642455101, discriminator loss: -0.3225424289703369\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 181/500, generator loss: -0.15077030658721924, discriminator loss: -0.31138917803764343\n","epoch: 182/500, generator loss: -0.34044572710990906, discriminator loss: -0.31759703159332275\n","epoch: 183/500, generator loss: -0.44260650873184204, discriminator loss: -0.30575186014175415\n","epoch: 184/500, generator loss: -0.1726122945547104, discriminator loss: -0.3101707100868225\n","epoch: 185/500, generator loss: -0.47044557332992554, discriminator loss: -0.30836257338523865\n","epoch: 186/500, generator loss: -0.3051857054233551, discriminator loss: -0.3130565881729126\n","epoch: 187/500, generator loss: 0.13025438785552979, discriminator loss: -0.3104228675365448\n","epoch: 188/500, generator loss: -0.7106881737709045, discriminator loss: -0.31566616892814636\n","epoch: 189/500, generator loss: -0.42741674184799194, discriminator loss: -0.30404412746429443\n","epoch: 190/500, generator loss: -0.206431046128273, discriminator loss: -0.3166347146034241\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 191/500, generator loss: -0.3183794319629669, discriminator loss: -0.2979184091091156\n","epoch: 192/500, generator loss: -0.8449392914772034, discriminator loss: -0.32337436079978943\n","epoch: 193/500, generator loss: -0.5944273471832275, discriminator loss: -0.3163267970085144\n","epoch: 194/500, generator loss: -0.1544577181339264, discriminator loss: -0.3078184425830841\n","epoch: 195/500, generator loss: 0.021319715306162834, discriminator loss: -0.30767717957496643\n","epoch: 196/500, generator loss: -0.42887917160987854, discriminator loss: -0.3057708442211151\n","epoch: 197/500, generator loss: -0.3392088711261749, discriminator loss: -0.2984039783477783\n","epoch: 198/500, generator loss: -0.3175511956214905, discriminator loss: -0.29825812578201294\n","epoch: 199/500, generator loss: -0.8223391175270081, discriminator loss: -0.2994456887245178\n","epoch: 200/500, generator loss: 0.12077938765287399, discriminator loss: -0.2990719676017761\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 201/500, generator loss: -0.16304759681224823, discriminator loss: -0.2870672047138214\n","epoch: 202/500, generator loss: -0.15663932263851166, discriminator loss: -0.2968585789203644\n","epoch: 203/500, generator loss: -0.39473119378089905, discriminator loss: -0.29212284088134766\n","epoch: 204/500, generator loss: -0.05171751603484154, discriminator loss: -0.29325538873672485\n","epoch: 205/500, generator loss: -0.8082541227340698, discriminator loss: -0.289049357175827\n","epoch: 206/500, generator loss: -0.05178660899400711, discriminator loss: -0.2922818660736084\n","epoch: 207/500, generator loss: -0.4538113474845886, discriminator loss: -0.3126436173915863\n","epoch: 208/500, generator loss: 0.0370437391102314, discriminator loss: -0.28774121403694153\n","epoch: 209/500, generator loss: -0.22488735616207123, discriminator loss: -0.2855145335197449\n","epoch: 210/500, generator loss: -0.21502923965454102, discriminator loss: -0.272225022315979\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 211/500, generator loss: -0.4559829533100128, discriminator loss: -0.2729346454143524\n","epoch: 212/500, generator loss: -0.221050426363945, discriminator loss: -0.27982524037361145\n","epoch: 213/500, generator loss: -0.3376520872116089, discriminator loss: -0.26604777574539185\n","epoch: 214/500, generator loss: -0.05695038661360741, discriminator loss: -0.2791692912578583\n","epoch: 215/500, generator loss: -0.2166644185781479, discriminator loss: -0.278327077627182\n","epoch: 216/500, generator loss: -0.33150047063827515, discriminator loss: -0.2747610807418823\n","epoch: 217/500, generator loss: -0.4937853515148163, discriminator loss: -0.28792959451675415\n","epoch: 218/500, generator loss: -0.0006981204496696591, discriminator loss: -0.28190717101097107\n","epoch: 219/500, generator loss: 0.15684638917446136, discriminator loss: -0.2833805978298187\n","epoch: 220/500, generator loss: -0.4363905191421509, discriminator loss: -0.2829829454421997\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 221/500, generator loss: 0.11840096861124039, discriminator loss: -0.2724052667617798\n","epoch: 222/500, generator loss: 0.28588926792144775, discriminator loss: -0.27829834818840027\n","epoch: 223/500, generator loss: -0.02542535588145256, discriminator loss: -0.29264119267463684\n","epoch: 224/500, generator loss: -0.52845698595047, discriminator loss: -0.28695985674858093\n","epoch: 225/500, generator loss: -0.10410516709089279, discriminator loss: -0.27292120456695557\n","epoch: 226/500, generator loss: -0.08783082664012909, discriminator loss: -0.2744331955909729\n","epoch: 227/500, generator loss: -0.10589323192834854, discriminator loss: -0.27722007036209106\n","epoch: 228/500, generator loss: -0.18113821744918823, discriminator loss: -0.2877630591392517\n","epoch: 229/500, generator loss: -0.5387848019599915, discriminator loss: -0.2842872738838196\n","epoch: 230/500, generator loss: -0.2937460243701935, discriminator loss: -0.27912747859954834\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 231/500, generator loss: -0.40533316135406494, discriminator loss: -0.2614396810531616\n","epoch: 232/500, generator loss: 0.35246941447257996, discriminator loss: -0.26062336564064026\n","epoch: 233/500, generator loss: -0.28875070810317993, discriminator loss: -0.27124783396720886\n","epoch: 234/500, generator loss: -0.552110493183136, discriminator loss: -0.27239030599594116\n","epoch: 235/500, generator loss: 0.08833199739456177, discriminator loss: -0.27255117893218994\n","epoch: 236/500, generator loss: 0.07416895031929016, discriminator loss: -0.26639246940612793\n","epoch: 237/500, generator loss: -0.5418870449066162, discriminator loss: -0.2624731659889221\n","epoch: 238/500, generator loss: -0.10595116019248962, discriminator loss: -0.26969969272613525\n","epoch: 239/500, generator loss: -0.0518672913312912, discriminator loss: -0.26104623079299927\n","epoch: 240/500, generator loss: 0.3298128843307495, discriminator loss: -0.2621799111366272\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 241/500, generator loss: -0.1253904402256012, discriminator loss: -0.2657153010368347\n","epoch: 242/500, generator loss: -0.09936875104904175, discriminator loss: -0.25293415784835815\n","epoch: 243/500, generator loss: -1.0029819011688232, discriminator loss: -0.27449262142181396\n","epoch: 244/500, generator loss: 0.08845977485179901, discriminator loss: -0.25513043999671936\n","epoch: 245/500, generator loss: 0.5073242783546448, discriminator loss: -0.2559696435928345\n","epoch: 246/500, generator loss: -0.32232311367988586, discriminator loss: -0.2670261859893799\n","epoch: 247/500, generator loss: -0.6154110431671143, discriminator loss: -0.2527495324611664\n","epoch: 248/500, generator loss: -0.17792785167694092, discriminator loss: -0.2664148807525635\n","epoch: 249/500, generator loss: 0.3667469620704651, discriminator loss: -0.2568954825401306\n","epoch: 250/500, generator loss: 0.2961067855358124, discriminator loss: -0.25765272974967957\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 251/500, generator loss: -0.15700238943099976, discriminator loss: -0.2521457076072693\n","epoch: 252/500, generator loss: -0.002324375556781888, discriminator loss: -0.24389511346817017\n","epoch: 253/500, generator loss: 0.037395235151052475, discriminator loss: -0.2701597511768341\n","epoch: 254/500, generator loss: -0.06023149937391281, discriminator loss: -0.26357701420783997\n","epoch: 255/500, generator loss: 0.1400282233953476, discriminator loss: -0.2527178227901459\n","epoch: 256/500, generator loss: -0.349421888589859, discriminator loss: -0.24168294668197632\n","epoch: 257/500, generator loss: -0.46017923951148987, discriminator loss: -0.22940990328788757\n","epoch: 258/500, generator loss: 0.34969398379325867, discriminator loss: -0.24575428664684296\n","epoch: 259/500, generator loss: 0.22872895002365112, discriminator loss: -0.2404995858669281\n","epoch: 260/500, generator loss: -0.2342403382062912, discriminator loss: -0.2385808378458023\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 261/500, generator loss: -0.4383777976036072, discriminator loss: -0.226775661110878\n","epoch: 262/500, generator loss: 0.8056266903877258, discriminator loss: -0.23870646953582764\n","epoch: 263/500, generator loss: -0.31899380683898926, discriminator loss: -0.2475312054157257\n","epoch: 264/500, generator loss: 0.010311048477888107, discriminator loss: -0.24620994925498962\n","epoch: 265/500, generator loss: -0.03053802065551281, discriminator loss: -0.2080518901348114\n","epoch: 266/500, generator loss: 0.8090783953666687, discriminator loss: -0.24456767737865448\n","epoch: 267/500, generator loss: 0.30034497380256653, discriminator loss: -0.22415438294410706\n","epoch: 268/500, generator loss: 0.3264264762401581, discriminator loss: -0.24389544129371643\n","epoch: 269/500, generator loss: -0.5664642453193665, discriminator loss: -0.2335326224565506\n","epoch: 270/500, generator loss: -0.21699248254299164, discriminator loss: -0.23075537383556366\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 271/500, generator loss: 0.4338352084159851, discriminator loss: -0.24261346459388733\n","epoch: 272/500, generator loss: 0.5035779476165771, discriminator loss: -0.2229691445827484\n","epoch: 273/500, generator loss: -0.047538723796606064, discriminator loss: -0.232876256108284\n","epoch: 274/500, generator loss: -0.02624025195837021, discriminator loss: -0.24326367676258087\n","epoch: 275/500, generator loss: 0.21925771236419678, discriminator loss: -0.24162979423999786\n","epoch: 276/500, generator loss: -0.36034953594207764, discriminator loss: -0.2376786321401596\n","epoch: 277/500, generator loss: 0.7124959230422974, discriminator loss: -0.24458417296409607\n","epoch: 278/500, generator loss: 0.07329072803258896, discriminator loss: -0.23049239814281464\n","epoch: 279/500, generator loss: -0.2854473888874054, discriminator loss: -0.2365652620792389\n","epoch: 280/500, generator loss: -0.19375981390476227, discriminator loss: -0.2277742326259613\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 281/500, generator loss: 1.0605216026306152, discriminator loss: -0.22375549376010895\n","epoch: 282/500, generator loss: -0.49736034870147705, discriminator loss: -0.23253852128982544\n","epoch: 283/500, generator loss: -0.0404801070690155, discriminator loss: -0.2289631962776184\n","epoch: 284/500, generator loss: 0.687813937664032, discriminator loss: -0.2358396202325821\n","epoch: 285/500, generator loss: 0.08178188651800156, discriminator loss: -0.22250603139400482\n","epoch: 286/500, generator loss: -0.18802472949028015, discriminator loss: -0.23020023107528687\n","epoch: 287/500, generator loss: 0.1377442479133606, discriminator loss: -0.21796241402626038\n","epoch: 288/500, generator loss: -0.1075282022356987, discriminator loss: -0.2259022295475006\n","epoch: 289/500, generator loss: 0.0293408315628767, discriminator loss: -0.23247121274471283\n","epoch: 290/500, generator loss: -0.10075821727514267, discriminator loss: -0.2389959841966629\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 291/500, generator loss: -0.07203700393438339, discriminator loss: -0.21648210287094116\n","epoch: 292/500, generator loss: 0.7110530138015747, discriminator loss: -0.23507852852344513\n","epoch: 293/500, generator loss: -0.14584267139434814, discriminator loss: -0.23800532519817352\n","epoch: 294/500, generator loss: -0.24796785414218903, discriminator loss: -0.2330138087272644\n","epoch: 295/500, generator loss: 0.7025209665298462, discriminator loss: -0.23783408105373383\n","epoch: 296/500, generator loss: 0.5759999752044678, discriminator loss: -0.23004303872585297\n","epoch: 297/500, generator loss: 0.01722034066915512, discriminator loss: -0.23288409411907196\n","epoch: 298/500, generator loss: -0.429488867521286, discriminator loss: -0.22349011898040771\n","epoch: 299/500, generator loss: 0.1970357745885849, discriminator loss: -0.21689429879188538\n","epoch: 300/500, generator loss: 0.13562993705272675, discriminator loss: -0.22718442976474762\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 301/500, generator loss: 0.3588813841342926, discriminator loss: -0.21259057521820068\n","epoch: 302/500, generator loss: 0.36077386140823364, discriminator loss: -0.21970656514167786\n","epoch: 303/500, generator loss: -0.35375115275382996, discriminator loss: -0.2109985649585724\n","epoch: 304/500, generator loss: -0.22792473435401917, discriminator loss: -0.21693287789821625\n","epoch: 305/500, generator loss: 0.1987810581922531, discriminator loss: -0.22390814125537872\n","epoch: 306/500, generator loss: 0.03848671168088913, discriminator loss: -0.21950767934322357\n","epoch: 307/500, generator loss: -0.24738100171089172, discriminator loss: -0.21896687150001526\n","epoch: 308/500, generator loss: -0.5231119990348816, discriminator loss: -0.2198440283536911\n","epoch: 309/500, generator loss: 0.41931092739105225, discriminator loss: -0.2198108583688736\n","epoch: 310/500, generator loss: 0.18997037410736084, discriminator loss: -0.21922503411769867\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 311/500, generator loss: 0.41218098998069763, discriminator loss: -0.2181798368692398\n","epoch: 312/500, generator loss: 0.4615022838115692, discriminator loss: -0.24239347875118256\n","epoch: 313/500, generator loss: -0.07422909885644913, discriminator loss: -0.2200758010149002\n","epoch: 314/500, generator loss: 0.0398583859205246, discriminator loss: -0.20406195521354675\n","epoch: 315/500, generator loss: -0.1875932514667511, discriminator loss: -0.21143239736557007\n","epoch: 316/500, generator loss: 0.1754760891199112, discriminator loss: -0.2083844244480133\n","epoch: 317/500, generator loss: 0.28176185488700867, discriminator loss: -0.20788751542568207\n","epoch: 318/500, generator loss: -0.1162542998790741, discriminator loss: -0.2155425101518631\n","epoch: 319/500, generator loss: 0.2993948757648468, discriminator loss: -0.2086155116558075\n","epoch: 320/500, generator loss: -0.3982418179512024, discriminator loss: -0.2135329693555832\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 321/500, generator loss: 0.33581840991973877, discriminator loss: -0.20396070182323456\n","epoch: 322/500, generator loss: -0.20945148169994354, discriminator loss: -0.20930546522140503\n","epoch: 323/500, generator loss: 0.05312761664390564, discriminator loss: -0.2038724571466446\n","epoch: 324/500, generator loss: -0.058472730219364166, discriminator loss: -0.20798487961292267\n","epoch: 325/500, generator loss: 0.4465108811855316, discriminator loss: -0.21406611800193787\n","epoch: 326/500, generator loss: 0.5377922654151917, discriminator loss: -0.208387091755867\n","epoch: 327/500, generator loss: 0.5158551335334778, discriminator loss: -0.19674736261367798\n","epoch: 328/500, generator loss: 0.05856505036354065, discriminator loss: -0.21530495584011078\n","epoch: 329/500, generator loss: -0.6124466061592102, discriminator loss: -0.20483367145061493\n","epoch: 330/500, generator loss: 0.199333056807518, discriminator loss: -0.18300433456897736\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 331/500, generator loss: 0.6372376084327698, discriminator loss: -0.18530194461345673\n","epoch: 332/500, generator loss: -0.5404518246650696, discriminator loss: -0.1882934868335724\n","epoch: 333/500, generator loss: 0.14474491775035858, discriminator loss: -0.20710043609142303\n","epoch: 334/500, generator loss: 0.25067901611328125, discriminator loss: -0.20190870761871338\n","epoch: 335/500, generator loss: -0.04839814081788063, discriminator loss: -0.19184499979019165\n","epoch: 336/500, generator loss: 0.14782583713531494, discriminator loss: -0.20565259456634521\n","epoch: 337/500, generator loss: 0.2648515999317169, discriminator loss: -0.1873546987771988\n","epoch: 338/500, generator loss: 0.27358508110046387, discriminator loss: -0.20409950613975525\n","epoch: 339/500, generator loss: -0.06191014125943184, discriminator loss: -0.19085940718650818\n","epoch: 340/500, generator loss: 0.7178957462310791, discriminator loss: -0.19799195230007172\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 341/500, generator loss: -0.09804855287075043, discriminator loss: -0.1869322508573532\n","epoch: 342/500, generator loss: 0.08353108167648315, discriminator loss: -0.20342935621738434\n","epoch: 343/500, generator loss: 0.4406264126300812, discriminator loss: -0.19358110427856445\n","epoch: 344/500, generator loss: 0.6642770171165466, discriminator loss: -0.19930393993854523\n","epoch: 345/500, generator loss: 0.3084307014942169, discriminator loss: -0.17781105637550354\n","epoch: 346/500, generator loss: -0.04768336936831474, discriminator loss: -0.1825171411037445\n","epoch: 347/500, generator loss: 0.27136701345443726, discriminator loss: -0.18631558120250702\n","epoch: 348/500, generator loss: 1.1613264083862305, discriminator loss: -0.20168812572956085\n","epoch: 349/500, generator loss: 0.48138439655303955, discriminator loss: -0.19694401323795319\n","epoch: 350/500, generator loss: -0.16439765691757202, discriminator loss: -0.1974295675754547\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 351/500, generator loss: 0.23867958784103394, discriminator loss: -0.20166411995887756\n","epoch: 352/500, generator loss: -0.42991265654563904, discriminator loss: -0.19736069440841675\n","epoch: 353/500, generator loss: 0.5333372354507446, discriminator loss: -0.1963420808315277\n","epoch: 354/500, generator loss: 0.609279453754425, discriminator loss: -0.19567477703094482\n","epoch: 355/500, generator loss: 0.11068706959486008, discriminator loss: -0.19034942984580994\n","epoch: 356/500, generator loss: 0.12014653533697128, discriminator loss: -0.20049959421157837\n","epoch: 357/500, generator loss: -0.10839416086673737, discriminator loss: -0.1958252191543579\n","epoch: 358/500, generator loss: 0.02155756950378418, discriminator loss: -0.2113688737154007\n","epoch: 359/500, generator loss: 0.050756484270095825, discriminator loss: -0.18406125903129578\n","epoch: 360/500, generator loss: 0.42969921231269836, discriminator loss: -0.17934465408325195\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 361/500, generator loss: 0.6180232763290405, discriminator loss: -0.1907750517129898\n","epoch: 362/500, generator loss: 0.6292219758033752, discriminator loss: -0.1857965886592865\n","epoch: 363/500, generator loss: 0.2735470235347748, discriminator loss: -0.2125951200723648\n","epoch: 364/500, generator loss: -0.004727968014776707, discriminator loss: -0.19696451723575592\n","epoch: 365/500, generator loss: 0.6737580299377441, discriminator loss: -0.18693800270557404\n","epoch: 366/500, generator loss: -0.05750267207622528, discriminator loss: -0.1844325214624405\n","epoch: 367/500, generator loss: -0.5335829257965088, discriminator loss: -0.19440704584121704\n","epoch: 368/500, generator loss: 0.520537257194519, discriminator loss: -0.19043785333633423\n","epoch: 369/500, generator loss: 0.6501269936561584, discriminator loss: -0.19619056582450867\n","epoch: 370/500, generator loss: 0.6430249214172363, discriminator loss: -0.19776777923107147\n","1/1 [==============================] - 0s 11ms/step\n","epoch: 371/500, generator loss: 0.26048851013183594, discriminator loss: -0.17837142944335938\n","epoch: 372/500, generator loss: 0.34228378534317017, discriminator loss: -0.19526539742946625\n","epoch: 373/500, generator loss: 0.17534245550632477, discriminator loss: -0.19450917840003967\n","epoch: 374/500, generator loss: 0.2338118553161621, discriminator loss: -0.16037705540657043\n","epoch: 375/500, generator loss: 0.9180135130882263, discriminator loss: -0.17785516381263733\n","epoch: 376/500, generator loss: 0.38128572702407837, discriminator loss: -0.18379980325698853\n","epoch: 377/500, generator loss: 0.22433677315711975, discriminator loss: -0.1898721158504486\n","epoch: 378/500, generator loss: 0.38974037766456604, discriminator loss: -0.1830468326807022\n","epoch: 379/500, generator loss: 0.6384180784225464, discriminator loss: -0.1827898919582367\n","epoch: 380/500, generator loss: 0.8039481043815613, discriminator loss: -0.17648525536060333\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 381/500, generator loss: 1.0712705850601196, discriminator loss: -0.18680483102798462\n","epoch: 382/500, generator loss: 0.30017849802970886, discriminator loss: -0.19654271006584167\n","epoch: 383/500, generator loss: -1.3168561458587646, discriminator loss: -0.1882813274860382\n","epoch: 384/500, generator loss: -0.2230892777442932, discriminator loss: -0.16648393869400024\n","epoch: 385/500, generator loss: 1.3204803466796875, discriminator loss: -0.18064658343791962\n","epoch: 386/500, generator loss: 0.7032001614570618, discriminator loss: -0.18347543478012085\n","epoch: 387/500, generator loss: -0.45762011408805847, discriminator loss: -0.18463054299354553\n","epoch: 388/500, generator loss: 0.2557140290737152, discriminator loss: -0.1797514259815216\n","epoch: 389/500, generator loss: 0.6123734712600708, discriminator loss: -0.15680554509162903\n","epoch: 390/500, generator loss: 0.8907662034034729, discriminator loss: -0.1627693474292755\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 391/500, generator loss: 0.390668660402298, discriminator loss: -0.16464820504188538\n","epoch: 392/500, generator loss: -0.8970782160758972, discriminator loss: -0.14457955956459045\n","epoch: 393/500, generator loss: 1.1658574342727661, discriminator loss: -0.15840667486190796\n","epoch: 394/500, generator loss: 1.3026987314224243, discriminator loss: -0.15151366591453552\n","epoch: 395/500, generator loss: 0.11222290247678757, discriminator loss: -0.16218140721321106\n","epoch: 396/500, generator loss: 0.5714236497879028, discriminator loss: -0.17012283205986023\n","epoch: 397/500, generator loss: 0.0900273323059082, discriminator loss: -0.1635233610868454\n","epoch: 398/500, generator loss: 0.2678030729293823, discriminator loss: -0.15472057461738586\n","epoch: 399/500, generator loss: 0.8845744132995605, discriminator loss: -0.16837415099143982\n","epoch: 400/500, generator loss: 0.238213449716568, discriminator loss: -0.16394314169883728\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 401/500, generator loss: -0.4846222698688507, discriminator loss: -0.17601212859153748\n","epoch: 402/500, generator loss: 0.44949430227279663, discriminator loss: -0.17145377397537231\n","epoch: 403/500, generator loss: 0.6401330232620239, discriminator loss: -0.17460140585899353\n","epoch: 404/500, generator loss: 0.5240382552146912, discriminator loss: -0.169035866856575\n","epoch: 405/500, generator loss: 0.4341330826282501, discriminator loss: -0.1795414686203003\n","epoch: 406/500, generator loss: 1.0144810676574707, discriminator loss: -0.1761465072631836\n","epoch: 407/500, generator loss: -0.36967647075653076, discriminator loss: -0.1801733672618866\n","epoch: 408/500, generator loss: -0.13278934359550476, discriminator loss: -0.16306769847869873\n","epoch: 409/500, generator loss: 1.1955647468566895, discriminator loss: -0.17187775671482086\n","epoch: 410/500, generator loss: 0.2630571126937866, discriminator loss: -0.1731874793767929\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 411/500, generator loss: -0.3053288161754608, discriminator loss: -0.18456321954727173\n","epoch: 412/500, generator loss: 0.06797181069850922, discriminator loss: -0.16742853820323944\n","epoch: 413/500, generator loss: -0.06433376669883728, discriminator loss: -0.16156691312789917\n","epoch: 414/500, generator loss: 1.4081450700759888, discriminator loss: -0.17262177169322968\n","epoch: 415/500, generator loss: 0.005057334899902344, discriminator loss: -0.17562496662139893\n","epoch: 416/500, generator loss: -0.19411493837833405, discriminator loss: -0.17222455143928528\n","epoch: 417/500, generator loss: 0.13336580991744995, discriminator loss: -0.1664121448993683\n","epoch: 418/500, generator loss: 0.5257129073143005, discriminator loss: -0.16505196690559387\n","epoch: 419/500, generator loss: 0.38294047117233276, discriminator loss: -0.16969524323940277\n","epoch: 420/500, generator loss: 0.9939154386520386, discriminator loss: -0.17802304029464722\n","1/1 [==============================] - 0s 11ms/step\n","epoch: 421/500, generator loss: 0.7657510638237, discriminator loss: -0.1634681075811386\n","epoch: 422/500, generator loss: 0.018897175788879395, discriminator loss: -0.17003265023231506\n","epoch: 423/500, generator loss: -0.22261521220207214, discriminator loss: -0.1681532859802246\n","epoch: 424/500, generator loss: -0.18142308294773102, discriminator loss: -0.15908175706863403\n","epoch: 425/500, generator loss: 1.1086103916168213, discriminator loss: -0.1558929681777954\n","epoch: 426/500, generator loss: 0.11235149949789047, discriminator loss: -0.15836459398269653\n","epoch: 427/500, generator loss: 0.8115357756614685, discriminator loss: -0.1682579070329666\n","epoch: 428/500, generator loss: -0.18860465288162231, discriminator loss: -0.1636790931224823\n","epoch: 429/500, generator loss: 0.9531363248825073, discriminator loss: -0.1717475801706314\n","epoch: 430/500, generator loss: 0.2958436906337738, discriminator loss: -0.1540759801864624\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 431/500, generator loss: -0.14083105325698853, discriminator loss: -0.16802166402339935\n","epoch: 432/500, generator loss: 1.1354302167892456, discriminator loss: -0.16805525124073029\n","epoch: 433/500, generator loss: 0.537352979183197, discriminator loss: -0.1472116857767105\n","epoch: 434/500, generator loss: -0.34056293964385986, discriminator loss: -0.15565143525600433\n","epoch: 435/500, generator loss: -0.7787104845046997, discriminator loss: -0.1370936632156372\n","epoch: 436/500, generator loss: 0.6866810917854309, discriminator loss: -0.16367016732692719\n","epoch: 437/500, generator loss: 1.0557034015655518, discriminator loss: -0.15058647096157074\n","epoch: 438/500, generator loss: 0.5780761241912842, discriminator loss: -0.16382263600826263\n","epoch: 439/500, generator loss: -0.14145825803279877, discriminator loss: -0.1570553481578827\n","epoch: 440/500, generator loss: -0.3061072826385498, discriminator loss: -0.14589740335941315\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 441/500, generator loss: 0.7571894526481628, discriminator loss: -0.16519609093666077\n","epoch: 442/500, generator loss: 0.1394502967596054, discriminator loss: -0.15035872161388397\n","epoch: 443/500, generator loss: 0.057780902832746506, discriminator loss: -0.16941963136196136\n","epoch: 444/500, generator loss: 0.2755467891693115, discriminator loss: -0.16831518709659576\n","epoch: 445/500, generator loss: 0.6117446422576904, discriminator loss: -0.15823611617088318\n","epoch: 446/500, generator loss: 0.6882654428482056, discriminator loss: -0.17010141909122467\n","epoch: 447/500, generator loss: -0.39656317234039307, discriminator loss: -0.14301550388336182\n","epoch: 448/500, generator loss: 0.26604634523391724, discriminator loss: -0.16688872873783112\n","epoch: 449/500, generator loss: 0.21793334186077118, discriminator loss: -0.1587427705526352\n","epoch: 450/500, generator loss: 1.3809926509857178, discriminator loss: -0.15547870099544525\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 451/500, generator loss: 0.3165333569049835, discriminator loss: -0.16199910640716553\n","epoch: 452/500, generator loss: 0.4958055019378662, discriminator loss: -0.17230141162872314\n","epoch: 453/500, generator loss: 0.03090958297252655, discriminator loss: -0.15108457207679749\n","epoch: 454/500, generator loss: 0.3439287841320038, discriminator loss: -0.1574661135673523\n","epoch: 455/500, generator loss: 0.44497403502464294, discriminator loss: -0.15477700531482697\n","epoch: 456/500, generator loss: 0.21812158823013306, discriminator loss: -0.15826649963855743\n","epoch: 457/500, generator loss: 0.4416418969631195, discriminator loss: -0.14985401928424835\n","epoch: 458/500, generator loss: 1.2781275510787964, discriminator loss: -0.16512928903102875\n","epoch: 459/500, generator loss: -0.25590425729751587, discriminator loss: -0.14866389334201813\n","epoch: 460/500, generator loss: -0.19943127036094666, discriminator loss: -0.1535499393939972\n","1/1 [==============================] - 0s 12ms/step\n","epoch: 461/500, generator loss: 0.4261387884616852, discriminator loss: -0.15899211168289185\n","epoch: 462/500, generator loss: 0.4553327262401581, discriminator loss: -0.1620907187461853\n","epoch: 463/500, generator loss: 0.785590410232544, discriminator loss: -0.14101359248161316\n","epoch: 464/500, generator loss: 0.38164234161376953, discriminator loss: -0.15015624463558197\n","epoch: 465/500, generator loss: 0.4859966039657593, discriminator loss: -0.15468324720859528\n","epoch: 466/500, generator loss: 0.5000638365745544, discriminator loss: -0.15549007058143616\n","epoch: 467/500, generator loss: 0.9912461042404175, discriminator loss: -0.1553138643503189\n","epoch: 468/500, generator loss: 0.466824471950531, discriminator loss: -0.14821621775627136\n","epoch: 469/500, generator loss: 0.29875004291534424, discriminator loss: -0.15107563138008118\n","epoch: 470/500, generator loss: 0.30194544792175293, discriminator loss: -0.1683843582868576\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 471/500, generator loss: 0.3484959006309509, discriminator loss: -0.15971074998378754\n","epoch: 472/500, generator loss: 0.19859477877616882, discriminator loss: -0.1584109663963318\n","epoch: 473/500, generator loss: 0.27506789565086365, discriminator loss: -0.148206889629364\n","epoch: 474/500, generator loss: 0.32871052622795105, discriminator loss: -0.14577345550060272\n","epoch: 475/500, generator loss: 0.44718170166015625, discriminator loss: -0.15037177503108978\n","epoch: 476/500, generator loss: 0.46355777978897095, discriminator loss: -0.16215969622135162\n","epoch: 477/500, generator loss: 0.46880602836608887, discriminator loss: -0.1502983123064041\n","epoch: 478/500, generator loss: 1.2238048315048218, discriminator loss: -0.16096803545951843\n","epoch: 479/500, generator loss: 0.833534836769104, discriminator loss: -0.15838025510311127\n","epoch: 480/500, generator loss: -0.5824827551841736, discriminator loss: -0.16469459235668182\n","1/1 [==============================] - 0s 13ms/step\n","epoch: 481/500, generator loss: -0.6562691926956177, discriminator loss: -0.14781227707862854\n","epoch: 482/500, generator loss: 1.2185652256011963, discriminator loss: -0.15301355719566345\n","epoch: 483/500, generator loss: 0.8157889246940613, discriminator loss: -0.15261787176132202\n","epoch: 484/500, generator loss: 0.7136115431785583, discriminator loss: -0.14263951778411865\n","epoch: 485/500, generator loss: 0.34954190254211426, discriminator loss: -0.15389500558376312\n","epoch: 486/500, generator loss: 0.3886338174343109, discriminator loss: -0.15242736041545868\n","epoch: 487/500, generator loss: 0.4150438904762268, discriminator loss: -0.1584976464509964\n","epoch: 488/500, generator loss: 0.6362169981002808, discriminator loss: -0.15421630442142487\n","epoch: 489/500, generator loss: 0.5321581959724426, discriminator loss: -0.14467450976371765\n","epoch: 490/500, generator loss: 0.8622830510139465, discriminator loss: -0.15517140924930573\n","1/1 [==============================] - 0s 11ms/step\n","epoch: 491/500, generator loss: 0.25663337111473083, discriminator loss: -0.1471327841281891\n","epoch: 492/500, generator loss: -0.3486603796482086, discriminator loss: -0.13767153024673462\n","epoch: 493/500, generator loss: 0.18535929918289185, discriminator loss: -0.14603553712368011\n","epoch: 494/500, generator loss: 1.349554181098938, discriminator loss: -0.1391076147556305\n","epoch: 495/500, generator loss: 0.753242015838623, discriminator loss: -0.1337636113166809\n","epoch: 496/500, generator loss: 0.4316321611404419, discriminator loss: -0.1263606995344162\n","epoch: 497/500, generator loss: 1.0487492084503174, discriminator loss: -0.1517067849636078\n","epoch: 498/500, generator loss: -0.16554604470729828, discriminator loss: -0.15259620547294617\n","epoch: 499/500, generator loss: -0.31568604707717896, discriminator loss: -0.11772793531417847\n","epoch: 500/500, generator loss: 0.08660540729761124, discriminator loss: -0.1121118813753128\n","1/1 [==============================] - 0s 12ms/step\n"]}],"source":["dataset = tf.keras.datasets.mnist\n","(x_train, y_train), (x_test, y_test) = dataset.load_data()\n","x_train = np.reshape(x_train, newshape=(-1, 28*28)) / 255.0\n","\n","gen = WGAN_GP()\n","gen.train(dataset=x_train)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP+wBU5jZ2yzDb/Qrj5euMu","gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
